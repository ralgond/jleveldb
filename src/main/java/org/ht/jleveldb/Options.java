package org.ht.jleveldb;

import org.ht.jleveldb.util.Cache;
import org.ht.jleveldb.util.Comparator0;

public class Options {

	/**
	 *  Parameters that affect behavior
	 */
	
	/**
	 * Comparator used to define the order of keys in the table.</br></br>
	 * Default: a comparator that uses lexicographic byte-wise ordering</br></br></br>
	  
	 * REQUIRES: The client must ensure that the comparator supplied
	 * here has the same name and orders keys *exactly* the same as the
	 * comparator provided to previous open calls on the same DB.
	 */
	public final Comparator0 comparator;
	
	/**
	 * If {@code true}, the database will be created if it is missing.</br></br>
	 * Default: {@code false}
	 */
	public boolean createIfMissing;
	
	/**
	 * If {@code true}, an error is raised if the database already exists.</br></br>
	 * Default: {@code false}
	 */
	public boolean errorIfExists;
	
	/**
	 * If true, the implementation will do aggressive checking of the
	 * data it is processing and will stop early if it detects any
	 * errors.</br></br>  
	 * 
	 * This may have unforeseen ramifications: for example, a
	 * corruption of one DB entry may cause a large number of entries to
	 * become unreadable or for the entire DB to become unopenable.</br></br>
	 * 
	 * Default: {@code false}
	 */
	public boolean paranoidChecks;
	 
	 /**
	  * Use the specified object to interact with the environment,
	  * e.g. to read/write files, schedule background work, etc.</br></br>
	  * 
	  * Default: {@link Env.defaultInstance}
	  */
	 public Env env;
	 
	 /**
	  *	Any internal progress/error information generated by the db will
	  * be written to infoLog if it is non-NULL, or to a file stored
	  * in the same directory as the DB contents if infoLog is null.</br></br>
	  * 
	  * Default: {@code null}
	  */
	 public Logger0 infoLog;
	  
	 
	 
	 /**
	  * Parameters that affect performance  
	  */
	 
	   
	 /**
	  * Amount of data to build up in memory (backed by an unsorted log
	  * on disk) before converting to a sorted on-disk file.</br></br>
	  
	  * Larger values increase performance, especially during bulk loads.
	  * Up to two write buffers may be held in memory at the same time,
	  * so you may wish to adjust this parameter to control memory usage.
	  * Also, a larger write buffer will result in a longer recovery time
	  * the next time the database is opened.</br></br>
	  
	  * Default: 4MB 
	  */
	 public int writeBufferSize;
	  
	 /**
	  * Number of open files that can be used by the DB.  You may need to
	  * increase this if your database has a large working set (budget
	  * one open file per 2MB of working set).</br></br>
	  *
	  * Default: 1000
	  */
	 public int maxOpenFiles;
	  
	 /**
	  * Control over blocks (user data is stored in a set of blocks, and
	  * a block is the unit of reading from disk).</br></br>
	  *
	  * If {@code non-null}, use the specified cache for blocks.</br>
	  * If {@code null}, jleveldb will automatically create and use an 8MB internal cache.</br></br>
	  * 
	  * Default: {@code null}
	  */
	 public Cache blockCache;
	 
	   
	 /**
	  * Approximate size of user data packed per block.</br>
	  * Note that the block size specified here corresponds to uncompressed data.</br>
	  * The actual size of the unit read from disk may be smaller if
	  * compression is enabled.  This parameter can be changed dynamically.</br></br>
	  *
	  * Default: 4K  
	  */
	 public int blockSize;
	 
	 /**
	  * Number of keys between restart points for delta encoding of keys.
	  * This parameter can be changed dynamically.  Most clients should
	  * leave this parameter alone.</br></br>
	  
	  * Default: 16 
	  */
	 public int blockRestartInterval;
	 
	   
	  /**
	   * jleveldb will write up to this amount of bytes to a file before
	   * switching to a new one.</br></br>
	   * Most clients should leave this parameter alone.  However if your
	   * filesystem is more efficient with larger files, you could
	   * consider increasing the value.</br></br>
	   * The downside will be longer compactions and hence longer latency/performance hiccups.</br></br>
	   * Another reason to increase this parameter might be when you are
	   * initially populating a large database.</br></br></br>
	   *
	   * Default: 2MB 
	   */
	 public int maxFileSize;
	  
	  /**
	   * Compress blocks using the specified compression algorithm.  This
	   * parameter can be changed dynamically.</br></br>
	   * 
	   * Default: {@link CompressionType.SnappyCompression}, which gives lightweight but fast
	   * compression.</br></br>
	  
	   * Typical speeds of SnappyCompression on an Intel(R) Core(TM)2 2.4GHz:</br>
	   *   ~200-500MB/s compression</br>
	   *   ~400-800MB/s decompression</br></br>
	   * Note that these speeds are significantly faster than most
	   * persistent storage speeds, and therefore it is typically never
	   * worth switching to kNoCompression.  Even if the input data is
	   * incompressible, the kSnappyCompression implementation will
	   * efficiently detect that and will switch to uncompressed mode.
	   */
	  public CompressionType compression;
	  
	  
	  /**
	   *  EXPERIMENTAL: If true, append to existing MANIFEST and log files
	   *  when a database is opened.  This can significantly speed up open.</br></br>
	   *  
	   *  Default: currently false, but may become true later.
	   */
	  public boolean reuseLogs;

	  /** If non-null, use the specified filter policy to reduce disk reads.
	   * Many applications will benefit from passing the result of
	   * NewBloomFilterPolicy() here.</br></br>
	   *
	   * Default: null
	   */
	  public FilterPolicy filterPolicy;
	  
	  public Options(Comparator0 comparator) {
		  this.comparator = comparator;
		  createIfMissing = false;
		  errorIfExists = false;
		  paranoidChecks = false;
		  env = null;
		  infoLog = null;
		  
		  writeBufferSize = 4*1024*1024;
		  maxOpenFiles = 1000;
		  blockCache = null;
		  blockSize = 4*1024;
		  blockRestartInterval = 16;
		  maxFileSize = 2*1024*1024;
		  compression = CompressionType.SnappyCompression;
	  }
	  
	  public Options cloneOptions() {
		  Options ret = new Options(comparator);
		  
		  ret.createIfMissing = createIfMissing;
		  ret.errorIfExists = errorIfExists;
		  ret.paranoidChecks = paranoidChecks;
		  ret.env = env;
		  ret.infoLog = infoLog;
		  
		  ret.writeBufferSize = writeBufferSize;
		  ret.maxOpenFiles = maxOpenFiles;
		  ret.blockCache = blockCache;
		  ret.blockSize = blockSize;
		  ret.blockRestartInterval = blockRestartInterval;
		  ret.maxFileSize = maxFileSize;
		  ret.compression = compression;
		  
		  return ret;
	  }
}
